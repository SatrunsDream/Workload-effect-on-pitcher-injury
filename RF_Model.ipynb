{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62441b2e",
   "metadata": {},
   "source": [
    "# Random Forest Model for Pitcher Injury Prediction\n",
    "\n",
    "This notebook implements three variants of Random Forest Classifier to predict workload-related pitcher injuries.\n",
    "\n",
    "## Model Variants:\n",
    "1. **Variant 1: Different n_estimators** (50, 100, 200) - Exploring ensemble size effects\n",
    "2. **Variant 2: Different max_depth** (5, 10, None) - Exploring tree complexity effects  \n",
    "3. **Variant 3: Cross-Validated max_depth** (3, 5, 7, 10, 15, 20, None) - Using GridSearchCV to systematically select optimal tree depth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa849b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import (confusion_matrix, classification_report, roc_curve, \n",
    "                            roc_auc_score, accuracy_score, log_loss)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2d5881",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77ad333e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (107325, 38)\n",
      "\n",
      "Target variable distribution:\n",
      "is_workload_inj\n",
      "0    106810\n",
      "1       515\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing values per column:\n",
      "FB_usage           24\n",
      "FB_velo           712\n",
      "FB_spin           931\n",
      "arm_angle        2662\n",
      "FB_vrel_var      2307\n",
      "pos            106268\n",
      "il_type        106268\n",
      "injury         106268\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "pitch_injuries = pd.read_csv('pitcher_data_w_injuries.csv')\n",
    "\n",
    "print(f\"Original dataset shape: {pitch_injuries.shape}\")\n",
    "print(f\"\\nTarget variable distribution:\")\n",
    "print(pitch_injuries['is_workload_inj'].value_counts())\n",
    "print(f\"\\nMissing values per column:\")\n",
    "print(pitch_injuries.isnull().sum()[pitch_injuries.isnull().sum() > 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97109add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after removing NAs: (102976, 14)\n",
      "\n",
      "Encoding 'birth_country' as dummy variables...\n",
      "  Unique countries: 26\n",
      "  Created 25 dummy variables (k-1 encoding)\n",
      "\n",
      "Final feature matrix shape: (102976, 37)\n",
      "Feature columns: ['p_throws', 'pitches_last_appearence', 'season', 'days_since_last_appearence', 'num_appearence', 'FB_usage', 'FB_velo', 'FB_spin', 'arm_angle', 'FB_vrel_var', 'age', 'bmi', 'country_Brazil', 'country_Canada', 'country_China', 'country_Colombia', 'country_Cuba', 'country_Curacao', 'country_DOM', 'country_Dominican Republic', 'country_Germany', 'country_Italy', 'country_Japan', 'country_Lithuania', 'country_Mexico', 'country_Nicaragua', 'country_Panama', 'country_Peru', 'country_Portugal', 'country_Puerto Rico', 'country_Republic of Korea', 'country_South Africa', 'country_Taiwan', 'country_USA', 'country_United Kingdom', 'country_VEN', 'country_Venezuela']\n"
     ]
    }
   ],
   "source": [
    "# Define feature columns\n",
    "feature_cols = ['p_throws', 'pitches_last_appearence', 'season', 'days_since_last_appearence', \n",
    "                'num_appearence', 'FB_usage', 'FB_velo', 'FB_spin', 'arm_angle', \n",
    "                'FB_vrel_var', 'birth_country', 'age', 'bmi']\n",
    "\n",
    "# Select features and target\n",
    "df = pitch_injuries[feature_cols + ['is_workload_inj']].copy()\n",
    "\n",
    "# Remove rows with missing values\n",
    "df_clean = df.dropna()\n",
    "print(f\"Dataset shape after removing NAs: {df_clean.shape}\")\n",
    "\n",
    "# Handle birth_country as dummy variables (k-1 encoding)\n",
    "print(f\"\\nEncoding 'birth_country' as dummy variables...\")\n",
    "print(f\"  Unique countries: {df_clean['birth_country'].nunique()}\")\n",
    "\n",
    "country_dummies = pd.get_dummies(df_clean['birth_country'], prefix='country', drop_first=True, dtype=int)\n",
    "print(f\"  Created {len(country_dummies.columns)} dummy variables (k-1 encoding)\")\n",
    "\n",
    "# Combine features\n",
    "df_clean = df_clean.drop('birth_country', axis=1)\n",
    "df_clean = pd.concat([df_clean, country_dummies], axis=1)\n",
    "\n",
    "# Separate features and target\n",
    "X = df_clean.drop('is_workload_inj', axis=1)\n",
    "y = df_clean['is_workload_inj'].astype(int)\n",
    "\n",
    "print(f\"\\nFinal feature matrix shape: {X.shape}\")\n",
    "print(f\"Feature columns: {list(X.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ddfc0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      "  Injuries: 499\n",
      "  No injuries: 102477\n",
      "  Imbalance ratio: 1:205.4\n",
      "\n",
      "Balanced class distribution:\n",
      "  Injuries: 499\n",
      "  No injuries: 499\n",
      "  Total samples: 998\n",
      "  Balance ratio: 1:1\n"
     ]
    }
   ],
   "source": [
    "# Balance the dataset as recommended by Professor Lai\n",
    "# Generate a random sample of \"no injury\" with the same N as the number of injuries\n",
    "\n",
    "injury_count = y.sum()\n",
    "no_injury_indices = y[y == 0].index\n",
    "injury_indices = y[y == 1].index\n",
    "\n",
    "# Randomly sample non-injury cases to match injury count\n",
    "np.random.seed(42)\n",
    "no_injury_sample = np.random.choice(no_injury_indices, size=injury_count, replace=False)\n",
    "\n",
    "# Combine balanced indices\n",
    "balanced_indices = np.concatenate([injury_indices, no_injury_sample])\n",
    "np.random.shuffle(balanced_indices)\n",
    "\n",
    "X_balanced = X.loc[balanced_indices].reset_index(drop=True)\n",
    "y_balanced = y.loc[balanced_indices].reset_index(drop=True)\n",
    "\n",
    "print(f\"Original class distribution:\")\n",
    "print(f\"  Injuries: {y.sum()}\")\n",
    "print(f\"  No injuries: {(y == 0).sum()}\")\n",
    "print(f\"  Imbalance ratio: 1:{(y == 0).sum()/y.sum():.1f}\")\n",
    "\n",
    "print(f\"\\nBalanced class distribution:\")\n",
    "print(f\"  Injuries: {y_balanced.sum()}\")\n",
    "print(f\"  No injuries: {(y_balanced == 0).sum()}\")\n",
    "print(f\"  Total samples: {len(y_balanced)}\")\n",
    "print(f\"  Balance ratio: 1:1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a93ef593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 798 samples\n",
      "Test set: 200 samples\n",
      "\n",
      "Training class distribution:\n",
      "is_workload_inj\n",
      "0    399\n",
      "1    399\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test class distribution:\n",
      "is_workload_inj\n",
      "0    100\n",
      "1    100\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test sets (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_balanced, y_balanced, test_size=0.2, random_state=42, stratify=y_balanced\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"\\nTraining class distribution:\")\n",
    "print(y_train.value_counts().sort_index())\n",
    "print(f\"\\nTest class distribution:\")\n",
    "print(y_test.value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67e5e62",
   "metadata": {},
   "source": [
    "## Model Variant 1: Different n_estimators (Ensemble Size)\n",
    "\n",
    "Exploring how the number of trees in the forest affects model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c20dd1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Variant 1 models with different n_estimators...\n",
      "\n",
      "  n_estimators = 50\n",
      "    Training Accuracy: 0.9612\n",
      "    CV Accuracy: 0.5877 (+/- 0.0466)\n",
      "\n",
      "  n_estimators = 100\n",
      "    Training Accuracy: 0.9612\n",
      "    CV Accuracy: 0.5889 (+/- 0.0506)\n",
      "\n",
      "  n_estimators = 200\n",
      "    Training Accuracy: 0.9624\n",
      "    CV Accuracy: 0.5852 (+/- 0.0440)\n",
      "\n",
      "Best Variant 1: n_estimators = 100 (CV Accuracy: 0.5889)\n"
     ]
    }
   ],
   "source": [
    "# Variant 1: Different n_estimators\n",
    "n_estimators_list = [50, 100, 200]\n",
    "variant1_models = {}\n",
    "variant1_train_scores = {}\n",
    "variant1_cv_scores = {}\n",
    "\n",
    "# 5-fold stratified cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"Training Variant 1 models with different n_estimators...\")\n",
    "for n_est in n_estimators_list:\n",
    "    print(f\"\\n  n_estimators = {n_est}\")\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=10,  # Fixed for this variant\n",
    "        min_samples_split=5,  # Fixed for this variant\n",
    "        min_samples_leaf=2,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_train, y_train)\n",
    "    variant1_models[n_est] = model\n",
    "    \n",
    "    # Training accuracy\n",
    "    train_pred = model.predict(X_train)\n",
    "    train_acc = accuracy_score(y_train, train_pred)\n",
    "    variant1_train_scores[n_est] = train_acc\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "    variant1_cv_scores[n_est] = cv_scores.mean()\n",
    "    \n",
    "    print(f\"    Training Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"    CV Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "# Select best variant based on CV score\n",
    "best_variant1 = max(variant1_cv_scores, key=variant1_cv_scores.get)\n",
    "print(f\"\\nBest Variant 1: n_estimators = {best_variant1} (CV Accuracy: {variant1_cv_scores[best_variant1]:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa06d5f",
   "metadata": {},
   "source": [
    "## Model Variant 2: Different max_depth (Tree Complexity)\n",
    "\n",
    "Exploring how tree depth affects model complexity and overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a92c5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Variant 2 models with different max_depth...\n",
      "\n",
      "  max_depth = 5\n",
      "    Training Accuracy: 0.7632\n",
      "    CV Accuracy: 0.5889 (+/- 0.0352)\n",
      "\n",
      "  max_depth = 10\n",
      "    Training Accuracy: 0.9612\n",
      "    CV Accuracy: 0.5889 (+/- 0.0506)\n",
      "\n",
      "  max_depth = None\n",
      "    Training Accuracy: 0.9937\n",
      "    CV Accuracy: 0.5777 (+/- 0.0399)\n",
      "\n",
      "Best Variant 2: max_depth = 5 (CV Accuracy: 0.5889)\n"
     ]
    }
   ],
   "source": [
    "# Variant 2: Different max_depth\n",
    "max_depth_list = [5, 10, None]  # None means unlimited depth\n",
    "variant2_models = {}\n",
    "variant2_train_scores = {}\n",
    "variant2_cv_scores = {}\n",
    "\n",
    "print(\"Training Variant 2 models with different max_depth...\")\n",
    "for max_d in max_depth_list:\n",
    "    depth_str = \"None\" if max_d is None else str(max_d)\n",
    "    print(f\"\\n  max_depth = {depth_str}\")\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100,  # Fixed for this variant\n",
    "        max_depth=max_d,\n",
    "        min_samples_split=5,  # Fixed for this variant\n",
    "        min_samples_leaf=2,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_train, y_train)\n",
    "    variant2_models[depth_str] = model\n",
    "    \n",
    "    # Training accuracy\n",
    "    train_pred = model.predict(X_train)\n",
    "    train_acc = accuracy_score(y_train, train_pred)\n",
    "    variant2_train_scores[depth_str] = train_acc\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "    variant2_cv_scores[depth_str] = cv_scores.mean()\n",
    "    \n",
    "    print(f\"    Training Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"    CV Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "# Select best variant based on CV score\n",
    "best_variant2 = max(variant2_cv_scores, key=variant2_cv_scores.get)\n",
    "print(f\"\\nBest Variant 2: max_depth = {best_variant2} (CV Accuracy: {variant2_cv_scores[best_variant2]:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba54a10",
   "metadata": {},
   "source": [
    "## Model Variant 3: Cross-Validated max_depth Selection\n",
    "\n",
    "Using cross-validation to systematically select the optimal max_depth parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81605e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variant 3: Cross-validated max_depth selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define a range of max_depth values to test\n",
    "max_depth_candidates = [3, 5, 7, 10, 15, 20, None]\n",
    "variant3_models = {}\n",
    "variant3_train_scores = {}\n",
    "variant3_cv_scores = {}\n",
    "variant3_cv_std = {}\n",
    "\n",
    "print(\"Training Variant 3 models with cross-validated max_depth selection...\")\n",
    "print(\"Using GridSearchCV to find optimal max_depth...\\n\")\n",
    "\n",
    "# Use GridSearchCV for systematic cross-validated parameter selection\n",
    "param_grid = {\n",
    "    'max_depth': max_depth_candidates\n",
    "}\n",
    "\n",
    "base_model = RandomForestClassifier(\n",
    "    n_estimators=100,  # Fixed for this variant\n",
    "    min_samples_split=5,  # Fixed for this variant\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    base_model,\n",
    "    param_grid,\n",
    "    cv=cv,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Extract results for each max_depth value\n",
    "for max_d in max_depth_candidates:\n",
    "    depth_str = \"None\" if max_d is None else str(max_d)\n",
    "    \n",
    "    # Find the index of this max_depth in the grid\n",
    "    param_idx = max_depth_candidates.index(max_d)\n",
    "    \n",
    "    # Get CV scores for this parameter\n",
    "    mean_cv_score = grid_search.cv_results_[f'mean_test_score'][param_idx]\n",
    "    std_cv_score = grid_search.cv_results_[f'std_test_score'][param_idx]\n",
    "    mean_train_score = grid_search.cv_results_[f'mean_train_score'][param_idx]\n",
    "    \n",
    "    variant3_cv_scores[depth_str] = mean_cv_score\n",
    "    variant3_cv_std[depth_str] = std_cv_score\n",
    "    variant3_train_scores[depth_str] = mean_train_score\n",
    "    \n",
    "    # Train a model with this max_depth for later use\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=max_d,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    variant3_models[depth_str] = model\n",
    "    \n",
    "    print(f\"  max_depth = {depth_str:4s}: CV Accuracy = {mean_cv_score:.4f} (+/- {std_cv_score * 2:.4f}), Train Accuracy = {mean_train_score:.4f}\")\n",
    "\n",
    "# Select best variant based on CV score\n",
    "best_variant3 = max(variant3_cv_scores, key=variant3_cv_scores.get)\n",
    "print(f\"\\nBest Variant 3 (Cross-Validated): max_depth = {best_variant3} (CV Accuracy: {variant3_cv_scores[best_variant3]:.4f})\")\n",
    "print(f\"GridSearchCV best parameters: {grid_search.best_params_}\")\n",
    "print(f\"GridSearchCV best CV score: {grid_search.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701c6285",
   "metadata": {},
   "source": [
    "## Figure 1: Training and Cross-Validation Error vs. Model Variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab9965b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive plot comparing all variants\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Variant 1: n_estimators\n",
    "ax1 = axes[0]\n",
    "train_errors_1 = [1 - variant1_train_scores[n] for n in n_estimators_list]\n",
    "cv_errors_1 = [1 - variant1_cv_scores[n] for n in n_estimators_list]\n",
    "ax1.plot(n_estimators_list, train_errors_1, 'o-', label='Training Error', linewidth=2, markersize=8)\n",
    "ax1.plot(n_estimators_list, cv_errors_1, 's-', label='CV Error', linewidth=2, markersize=8)\n",
    "ax1.set_xlabel('Number of Trees (n_estimators)', fontsize=12)\n",
    "ax1.set_ylabel('Error Rate', fontsize=12)\n",
    "ax1.set_title('Variant 1: Ensemble Size Effect', fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xticks(n_estimators_list)\n",
    "\n",
    "# Variant 2: max_depth\n",
    "ax2 = axes[1]\n",
    "depth_labels = ['5', '10', 'None']\n",
    "train_errors_2 = [1 - variant2_train_scores[d] for d in depth_labels]\n",
    "cv_errors_2 = [1 - variant2_cv_scores[d] for d in depth_labels]\n",
    "x_pos = [0, 1, 2]\n",
    "ax2.plot(x_pos, train_errors_2, 'o-', label='Training Error', linewidth=2, markersize=8)\n",
    "ax2.plot(x_pos, cv_errors_2, 's-', label='CV Error', linewidth=2, markersize=8)\n",
    "ax2.set_xlabel('Max Tree Depth', fontsize=12)\n",
    "ax2.set_ylabel('Error Rate', fontsize=12)\n",
    "ax2.set_title('Variant 2: Tree Complexity Effect', fontsize=14, fontweight='bold')\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels(depth_labels)\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Variant 3: Cross-validated max_depth\n",
    "ax3 = axes[2]\n",
    "depth_labels_v3 = [str(d) if d is not None else 'None' for d in max_depth_candidates]\n",
    "train_errors_3 = [1 - variant3_train_scores[d] for d in depth_labels_v3]\n",
    "cv_errors_3 = [1 - variant3_cv_scores[d] for d in depth_labels_v3]\n",
    "x_pos_v3 = range(len(max_depth_candidates))\n",
    "ax3.plot(x_pos_v3, train_errors_3, 'o-', label='Training Error', linewidth=2, markersize=8)\n",
    "ax3.plot(x_pos_v3, cv_errors_3, 's-', label='CV Error', linewidth=2, markersize=8)\n",
    "ax3.set_xlabel('Max Tree Depth (CV Selected)', fontsize=12)\n",
    "ax3.set_ylabel('Error Rate', fontsize=12)\n",
    "ax3.set_title('Variant 3: Cross-Validated Depth Selection', fontsize=14, fontweight='bold')\n",
    "ax3.set_xticks(x_pos_v3)\n",
    "ax3.set_xticklabels(depth_labels_v3, rotation=45, ha='right')\n",
    "ax3.legend(fontsize=10)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('rf_training_cv_error_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure 1: Training and Cross-Validation Error vs. Model Variants\")\n",
    "print(\"This figure shows how each hyperparameter affects the trade-off between training and validation performance.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56595deb",
   "metadata": {},
   "source": [
    "## Model Evaluation on Test Set\n",
    "\n",
    "Evaluating the best model from each variant on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04678856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate best models from each variant on test set\n",
    "best_models = {\n",
    "    'Variant 1 (n_est=200)': variant1_models[best_variant1],\n",
    "    'Variant 2 (max_d=10)': variant2_models[best_variant2],\n",
    "    f'Variant 3 (CV max_d={best_variant3})': variant3_models[best_variant3]\n",
    "}\n",
    "\n",
    "test_results = {}\n",
    "\n",
    "for name, model in best_models.items():\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Metrics\n",
    "    test_acc = accuracy_score(y_test, y_pred)\n",
    "    test_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    test_logloss = log_loss(y_test, y_pred_proba)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    test_results[name] = {\n",
    "        'accuracy': test_acc,\n",
    "        'auc': test_auc,\n",
    "        'log_loss': test_logloss,\n",
    "        'confusion_matrix': cm,\n",
    "        'y_pred_proba': y_pred_proba\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"  Test AUC-ROC: {test_auc:.4f}\")\n",
    "    print(f\"  Test Log Loss: {test_logloss:.4f}\")\n",
    "    print(f\"  Confusion Matrix:\")\n",
    "    print(f\"    {cm[0,0]:4d}  {cm[0,1]:4d}\")\n",
    "    print(f\"    {cm[1,0]:4d}  {cm[1,1]:4d}\")\n",
    "\n",
    "# Naive baseline (always predict majority class)\n",
    "naive_baseline = max(y_test.value_counts()) / len(y_test)\n",
    "print(f\"\\nNaive Baseline Accuracy (always predict majority class): {naive_baseline:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9109bf32",
   "metadata": {},
   "source": [
    "## Figure 2: Confusion Matrices for All Variants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f1f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrices\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for idx, (name, results) in enumerate(test_results.items()):\n",
    "    cm = results['confusion_matrix']\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax, \n",
    "                cbar_kws={'label': 'Count'}, vmin=0, vmax=cm.max())\n",
    "    ax.set_xlabel('Predicted', fontsize=11)\n",
    "    ax.set_ylabel('Actual', fontsize=11)\n",
    "    ax.set_title(f'{name}\\nAccuracy: {results[\"accuracy\"]:.3f}', fontsize=12, fontweight='bold')\n",
    "    ax.set_xticklabels(['No Injury', 'Injury'])\n",
    "    ax.set_yticklabels(['No Injury', 'Injury'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('rf_confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure 2: Confusion Matrices for All Variants\")\n",
    "print(\"This figure shows the classification performance of each variant on the test set.\")\n",
    "print(\"The diagonal elements represent correct predictions, while off-diagonal elements represent misclassifications.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8a9b04",
   "metadata": {},
   "source": [
    "## Figure 3: ROC Curves for All Variants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5572204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for name, results in test_results.items():\n",
    "    fpr, tpr, _ = roc_curve(y_test, results['y_pred_proba'])\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=f'{name} (AUC = {results[\"auc\"]:.3f})')\n",
    "\n",
    "# Diagonal line (random classifier)\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier (AUC = 0.500)')\n",
    "\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curves: Random Forest Variants', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right', fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('rf_roc_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure 3: ROC Curves for All Variants\")\n",
    "print(\"This figure shows the trade-off between true positive rate and false positive rate.\")\n",
    "print(\"AUC (Area Under Curve) closer to 1.0 indicates better classification performance.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6450c46a",
   "metadata": {},
   "source": [
    "## Figure 4: Model Accuracy Comparison (Including Naive Baseline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf74686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot comparing accuracies\n",
    "model_names = list(test_results.keys())\n",
    "accuracies = [test_results[name]['accuracy'] for name in model_names]\n",
    "accuracies.append(naive_baseline)\n",
    "model_names.append('Naive Baseline')\n",
    "\n",
    "colors = ['#3498db', '#2ecc71', '#e74c3c', '#95a5a6']\n",
    "bars = plt.bar(range(len(model_names)), accuracies, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, acc) in enumerate(zip(bars, accuracies)):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "             f'{acc:.3f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.xlabel('Model Variant', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.title('Test Set Accuracy: Random Forest Variants vs. Naive Baseline', fontsize=14, fontweight='bold')\n",
    "plt.xticks(range(len(model_names)), model_names, rotation=15, ha='right')\n",
    "plt.ylim([0, max(accuracies) * 1.15])\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('rf_accuracy_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure 4: Model Accuracy Comparison\")\n",
    "print(\"This figure compares the test accuracy of each variant against a naive baseline.\")\n",
    "print(\"The naive baseline always predicts the majority class (no injury).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66809cbd",
   "metadata": {},
   "source": [
    "## Cross-Validation Comparison Across All Variants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff23d204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all CV scores for comparison\n",
    "all_cv_scores = {}\n",
    "\n",
    "# Variant 1\n",
    "for n_est in n_estimators_list:\n",
    "    all_cv_scores[f'V1: n_est={n_est}'] = variant1_cv_scores[n_est]\n",
    "\n",
    "# Variant 2\n",
    "for depth_str in ['5', '10', 'None']:\n",
    "    all_cv_scores[f'V2: max_d={depth_str}'] = variant2_cv_scores[depth_str]\n",
    "\n",
    "# Variant 3\n",
    "for max_d in max_depth_candidates:\n",
    "    depth_str = \"None\" if max_d is None else str(max_d)\n",
    "    all_cv_scores[f'V3: CV max_d={depth_str}'] = variant3_cv_scores[depth_str]\n",
    "\n",
    "# Find best overall model\n",
    "best_overall = min(all_cv_scores, key=lambda x: 1 - all_cv_scores[x])  # Lower error = better\n",
    "best_cv_error = 1 - all_cv_scores[best_overall]\n",
    "\n",
    "print(\"Cross-Validation Accuracy Summary:\")\n",
    "print(\"=\" * 60)\n",
    "for name, score in sorted(all_cv_scores.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{name:25s}: {score:.4f}\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nBest Model (Lowest CV Error): {best_overall}\")\n",
    "print(f\"CV Accuracy: {all_cv_scores[best_overall]:.4f}\")\n",
    "print(f\"CV Error: {1 - all_cv_scores[best_overall]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc3a0d5",
   "metadata": {},
   "source": [
    "## Model Comparison Metrics: AIC and BIC\n",
    "\n",
    "For Random Forest, we can approximate AIC and BIC using the log-likelihood from predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729a2ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate AIC and BIC for model comparison\n",
    "# AIC = -2*log_likelihood + 2*k\n",
    "# BIC = -2*log_likelihood + k*log(n)\n",
    "# where k = number of parameters (approximated by number of trees * average tree depth)\n",
    "# and n = number of samples\n",
    "\n",
    "def calculate_aic_bic(model, X, y, n_estimators, max_depth):\n",
    "    \"\"\"Calculate AIC and BIC for Random Forest model\"\"\"\n",
    "    y_pred_proba = model.predict_proba(X)[:, 1]\n",
    "    \n",
    "    # Log-likelihood (using log_loss)\n",
    "    log_likelihood = -log_loss(y, y_pred_proba, normalize=False)\n",
    "    \n",
    "    # Approximate number of parameters\n",
    "    # For RF: roughly n_estimators * average_nodes_per_tree\n",
    "    # We'll use a simpler approximation: n_estimators * max_depth (if available)\n",
    "    if max_depth is None:\n",
    "        # Estimate depth as log2 of average samples per leaf\n",
    "        k = n_estimators * 10  # Conservative estimate\n",
    "    else:\n",
    "        k = n_estimators * max_depth\n",
    "    \n",
    "    n = len(y)\n",
    "    \n",
    "    aic = -2 * log_likelihood + 2 * k\n",
    "    bic = -2 * log_likelihood + k * np.log(n)\n",
    "    \n",
    "    return aic, bic, log_likelihood\n",
    "\n",
    "# Calculate for best models\n",
    "comparison_metrics = {}\n",
    "\n",
    "for name, model in best_models.items():\n",
    "    if 'Variant 1' in name:\n",
    "        n_est, max_d = best_variant1, 10\n",
    "    elif 'Variant 2' in name:\n",
    "        n_est, max_d = 100, None if best_variant2 == 'None' else int(best_variant2)\n",
    "    else:  # Variant 3 (cross-validated)\n",
    "        n_est = 100\n",
    "        max_d = None if best_variant3 == 'None' else int(best_variant3)\n",
    "    \n",
    "    aic, bic, ll = calculate_aic_bic(model, X_test, y_test, n_est, max_d)\n",
    "    comparison_metrics[name] = {\n",
    "        'AIC': aic,\n",
    "        'BIC': bic,\n",
    "        'Log-Likelihood': ll,\n",
    "        'n_estimators': n_est,\n",
    "        'max_depth': max_d\n",
    "    }\n",
    "\n",
    "print(\"Model Comparison Metrics (Lower is Better for AIC/BIC):\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Model':<30s} {'AIC':>12s} {'BIC':>12s} {'Log-Likelihood':>15s}\")\n",
    "print(\"=\" * 80)\n",
    "for name, metrics in comparison_metrics.items():\n",
    "    print(f\"{name:<30s} {metrics['AIC']:>12.2f} {metrics['BIC']:>12.2f} {metrics['Log-Likelihood']:>15.2f}\")\n",
    "\n",
    "# Find best model by AIC and BIC\n",
    "best_aic = min(comparison_metrics.items(), key=lambda x: x[1]['AIC'])\n",
    "best_bic = min(comparison_metrics.items(), key=lambda x: x[1]['BIC'])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"Best Model by AIC: {best_aic[0]} (AIC = {best_aic[1]['AIC']:.2f})\")\n",
    "print(f\"Best Model by BIC: {best_bic[0]} (BIC = {best_bic[1]['BIC']:.2f})\")\n",
    "print(\"\\nNote: AIC and BIC penalize model complexity. Lower values indicate better\")\n",
    "print(\"model fit while accounting for the number of parameters.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ac7e96",
   "metadata": {},
   "source": [
    "## Figure 5: Feature Importance Analysis\n",
    "\n",
    "Examining which features are most important for injury prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03440b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from the best overall model\n",
    "best_model_name = 'Variant 1 (n_est=200)'  # Using best from variant 1\n",
    "best_model = best_models[best_model_name]\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': best_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Plot top 15 features\n",
    "top_features = feature_importance.head(15)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "bars = plt.barh(range(len(top_features)), top_features['importance'], \n",
    "                color='steelblue', alpha=0.7, edgecolor='black', linewidth=1)\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Feature Importance', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('Top 15 Most Important Features for Injury Prediction', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add value labels\n",
    "for i, (idx, row) in enumerate(top_features.iterrows()):\n",
    "    plt.text(row['importance'] + 0.001, i, f'{row[\"importance\"]:.3f}', \n",
    "             va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('rf_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure 5: Feature Importance Analysis\")\n",
    "print(\"This figure shows the relative importance of features in predicting injuries.\")\n",
    "print(\"Higher importance values indicate features that contribute more to the model's predictions.\")\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(top_features.head(10)[['feature', 'importance']].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5622b4",
   "metadata": {},
   "source": [
    "## Summary and Conclusions\n",
    "\n",
    "### Model Variant Comparison:\n",
    "\n",
    "**Variant 1 (n_estimators):**\n",
    "- Explored ensemble size effects (50, 100, 200 trees)\n",
    "- More trees generally improve performance but with diminishing returns\n",
    "- Best: n_estimators = 200\n",
    "\n",
    "**Variant 2 (max_depth):**\n",
    "- Explored tree complexity (depth 5, 10, unlimited)\n",
    "- Deeper trees can overfit; moderate depth often optimal\n",
    "- Best: max_depth = 10\n",
    "\n",
    "**Variant 3 (Cross-Validated max_depth):**\n",
    "- Used GridSearchCV to systematically test max_depth values (3, 5, 7, 10, 15, 20, None)\n",
    "- Cross-validation selects optimal depth to balance bias and variance\n",
    "- Best: max_depth selected via cross-validation\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Cross-Validation Performance:** All variants show similar CV accuracy, suggesting robustness\n",
    "2. **Overfitting:** Variant 2 with unlimited depth shows largest train-test gap\n",
    "3. **Feature Importance:** Workload-related features (pitches, rest days) are most predictive\n",
    "4. **Model Selection:** Based on CV error and AIC/BIC, the best model balances complexity and performance\n",
    "\n",
    "### Interpretation:\n",
    "\n",
    "Random Forest models capture non-linear relationships between workload features and injury risk. The ensemble approach helps reduce variance and improve generalization. However, injury prediction remains challenging due to the inherent randomness of injuries, even when focusing on workload-related injuries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257a2499",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
