{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5be2650",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WebScraping\n",
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "import re\n",
    "import io\n",
    "from typing import Optional\n",
    "from typing import Optional, Dict, List, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74d8b790",
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADERS = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/118.0.0.0 Safari/537.36\"\n",
    "    ),\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "}\n",
    "\n",
    "def build_url(year: int) -> str:\n",
    "    return f\"https://www.spotrac.com/mlb/injured/_/year/{year}/view/player\"\n",
    "\n",
    "def fetch_html(url: str, max_retries: int = 3, backoff: float = 2.0) -> Optional[str]:\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            resp = requests.get(url, headers=HEADERS, timeout=20)\n",
    "            if resp.status_code == 200 and \"text/html\" in resp.headers.get(\"Content-Type\", \"\"):\n",
    "                return resp.text\n",
    "            if resp.status_code in (403, 429, 503):\n",
    "                time.sleep(backoff * attempt)\n",
    "                continue\n",
    "            break\n",
    "        except requests.RequestException:\n",
    "            time.sleep(backoff * attempt)\n",
    "    return None\n",
    "\n",
    "def parse_table_with_pandas(html: str) -> Optional[pd.DataFrame]:\n",
    "    try:\n",
    "        # Use StringIO to avoid the literal-HTML FutureWarning\n",
    "        tables = pd.read_html(io.StringIO(html))\n",
    "        if not tables:\n",
    "            return None\n",
    "        return max(tables, key=lambda t: t.shape[1])  # pick widest table\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def parse_table_with_bs4(html: str) -> Optional[pd.DataFrame]:\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    table = soup.find(\"table\")\n",
    "    if not table:\n",
    "        return None\n",
    "\n",
    "    thead = table.find(\"thead\")\n",
    "    if thead:\n",
    "        headers = [th.get_text(strip=True) for th in thead.find_all(\"th\")]\n",
    "    else:\n",
    "        first_row = table.find(\"tr\")\n",
    "        headers = [th.get_text(strip=True) for th in first_row.find_all([\"th\", \"td\"])] if first_row else []\n",
    "\n",
    "    rows = []\n",
    "    for tr in table.find_all(\"tr\"):\n",
    "        tds = tr.find_all(\"td\")\n",
    "        if not tds:\n",
    "            continue\n",
    "        rows.append([td.get_text(\" \", strip=True) for td in tds])\n",
    "\n",
    "    if not rows:\n",
    "        return None\n",
    "\n",
    "    max_len = max(len(r) for r in rows)\n",
    "    if len(headers) != max_len:\n",
    "        if len(headers) < max_len:\n",
    "            headers += [f\"col_{i+1}\" for i in range(len(headers), max_len)]\n",
    "        else:\n",
    "            headers = headers[:max_len]\n",
    "\n",
    "    return pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "def clean_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.columns = [c.strip().replace(\"\\n\", \" \").replace(\"  \", \" \") for c in df.columns]\n",
    "    df = df.dropna(axis=1, how=\"all\")\n",
    "    df = df.replace(\"\", pd.NA).dropna(how=\"all\")\n",
    "    return df\n",
    "\n",
    "def try_requests_then_playwright(url: str) -> pd.DataFrame:\n",
    "    html = fetch_html(url)\n",
    "    if html:\n",
    "        for parser in (parse_table_with_pandas, parse_table_with_bs4):\n",
    "            df = parser(html)\n",
    "            if isinstance(df, pd.DataFrame) and not df.empty:\n",
    "                return clean_df(df)\n",
    "\n",
    "    # Fallback to Playwright (optional dependency)\n",
    "    try:\n",
    "        from playwright.sync_api import sync_playwright\n",
    "    except ImportError as e:\n",
    "        raise RuntimeError(\n",
    "            \"Requests parsing failed and Playwright is not installed.\\n\"\n",
    "            \"Install with:\\n  pip install playwright\\n  playwright install chromium\"\n",
    "        ) from e\n",
    "\n",
    "    with sync_playwright() as p:\n",
    "        browser = p.chromium.launch(headless=True)\n",
    "        context = browser.new_context(user_agent=HEADERS[\"User-Agent\"])\n",
    "        page = context.new_page()\n",
    "        page.goto(url, wait_until=\"domcontentloaded\", timeout=45000)\n",
    "        page.wait_for_selector(\"table\", timeout=20000)\n",
    "        content = page.content()\n",
    "        browser.close()\n",
    "\n",
    "    for parser in (parse_table_with_pandas, parse_table_with_bs4):\n",
    "        df = parser(content)\n",
    "        if isinstance(df, pd.DataFrame) and not df.empty:\n",
    "            return clean_df(df)\n",
    "\n",
    "    raise RuntimeError(\"Could not locate a data table on the page after rendering.\")\n",
    "\n",
    "# ---------------- Normalizer ----------------\n",
    "\n",
    "def _pick(df, *cands):\n",
    "    cand_lc = [c.lower() for c in df.columns]\n",
    "    for want in cands:\n",
    "        for i, c in enumerate(cand_lc):\n",
    "            if want in c:\n",
    "                return df.columns[i]\n",
    "    return None\n",
    "\n",
    "def normalize_spotrac_injured_df(raw: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = raw.copy()\n",
    "\n",
    "    col_rank   = _pick(df, \"rank\")\n",
    "    col_player = _pick(df, \"player\")\n",
    "    col_pos    = _pick(df, \"pos\")\n",
    "    col_team   = _pick(df, \"team\")\n",
    "    col_reason = _pick(df, \"reason\")\n",
    "    col_days   = _pick(df, \"days\")       \n",
    "    col_cash   = _pick(df, \"cash\", \"total\")\n",
    "\n",
    "    if any(c is None for c in [col_player, col_reason]):\n",
    "        raise ValueError(f\"Missing required columns. Found: {list(df.columns)}\")\n",
    "\n",
    "    out = pd.DataFrame()\n",
    "    if col_rank:   out[\"rank\"]   = pd.to_numeric(df[col_rank], errors=\"coerce\").astype(\"Int64\")\n",
    "    out[\"player\"]  = df[col_player].astype(str).str.strip()\n",
    "    if col_pos:    out[\"pos\"]    = df[col_pos].astype(str).str.strip()\n",
    "    if col_team:   out[\"team\"]   = df[col_team].astype(str).str.strip()\n",
    "\n",
    "    reason = df[col_reason].astype(str).str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "    out[\"reason_raw\"] = reason\n",
    "\n",
    "    rx1 = re.compile(\n",
    "        r\"^(?P<il>[^:]+?IL|[^:]+?List|Suspension|Restricted(?: List)?)\"\n",
    "        r\"(?:\\s*-\\s*(?P<inj>[^:]+?))?\"\n",
    "        r\"(?:\\s*:\\s*(?P<start>\\d{1,2}/\\d{1,2}/\\d{2}))?\"\n",
    "        r\"(?:-(?P<end>\\d{1,2}/\\d{1,2}/\\d{2}))?$\",\n",
    "        flags=re.IGNORECASE\n",
    "    )\n",
    "    rx2 = re.compile(\n",
    "        r\"^(?P<il>[^:]+?)\"\n",
    "        r\"(?:\\s*-\\s*(?P<inj>[^:]+?))?\"\n",
    "        r\"(?:\\s*:\\s*(?P<start>\\d{1,2}/\\d{1,2}/\\d{2}))?\"\n",
    "        r\"(?:-(?P<end>\\d{1,2}/\\d{1,2}/\\d{2}))?$\",\n",
    "        flags=re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    ext  = reason.str.extract(rx1)\n",
    "    ext2 = reason.str.extract(rx2)\n",
    "\n",
    "    for k in [\"il\", \"inj\", \"start\", \"end\"]:\n",
    "        out[k] = ext[k].where(ext[k].notna(), ext2[k])\n",
    "\n",
    "    out = out.rename(columns={\"il\": \"il_type\", \"inj\": \"injury\"})\n",
    "    out[\"il_type\"] = out[\"il_type\"].astype(str).str.strip()\n",
    "    out[\"injury\"]  = out[\"injury\"].astype(str).str.strip()\n",
    "\n",
    "    for k in [\"start\", \"end\"]:\n",
    "        out[k + \"_date\"] = pd.to_datetime(out[k], format=\"%m/%d/%y\", errors=\"coerce\")\n",
    "    out = out.drop(columns=[\"start\", \"end\"])\n",
    "\n",
    "    if col_days:\n",
    "        out[\"days_missed\"] = pd.to_numeric(\n",
    "            df[col_days].astype(str).str.replace(r\"[^\\d]\", \"\", regex=True),\n",
    "            errors=\"coerce\"\n",
    "        ).astype(\"Int64\")\n",
    "\n",
    "    if col_cash:\n",
    "        out[\"cash_total\"] = (\n",
    "            df[col_cash].astype(str)\n",
    "            .str.replace(r\"[$,]\", \"\", regex=True)\n",
    "            .str.extract(r\"([\\d.]+)\")[0]\n",
    "            .pipe(pd.to_numeric, errors=\"coerce\")\n",
    "        )\n",
    "\n",
    "    if \"cash_total\" in out and \"days_missed\" in out:\n",
    "        out[\"cash_per_day\"] = (out[\"cash_total\"] / out[\"days_missed\"].astype(float)).round(2)\n",
    "\n",
    "    cols = [\"rank\", \"player\", \"pos\", \"team\",\n",
    "            \"il_type\", \"injury\", \"start_date\", \"end_date\",\n",
    "            \"days_missed\", \"cash_total\", \"cash_per_day\", \"reason_raw\"]\n",
    "    cols = [c for c in cols if c in out.columns]\n",
    "    return out[cols]\n",
    "\n",
    "# ---------------- Multi-year API (no autosave) ----------------\n",
    "\n",
    "def scrape_spotrac_years(years: List[int], sleep_sec: float = 1.0) -> Tuple[Dict[int, pd.DataFrame], pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Scrape and normalize Spotrac MLB Injured List for multiple years.\n",
    "    Returns:\n",
    "      - tables: {year: cleaned DataFrame}\n",
    "      - combined: single DataFrame with a 'year' column\n",
    "    Does NOT write to disk.\n",
    "    \"\"\"\n",
    "    tables: Dict[int, pd.DataFrame] = {}\n",
    "    frames = []\n",
    "    for yr in years:\n",
    "        url = build_url(yr)\n",
    "        raw = try_requests_then_playwright(url)\n",
    "        clean = normalize_spotrac_injured_df(raw)\n",
    "        clean = clean.assign(year=yr)\n",
    "        tables[yr] = clean\n",
    "        frames.append(clean)\n",
    "        if sleep_sec:\n",
    "            time.sleep(sleep_sec)  # be polite to the site\n",
    "    combined = pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()\n",
    "    return tables, combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f5a9bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>player</th>\n",
       "      <th>pos</th>\n",
       "      <th>team</th>\n",
       "      <th>il_type</th>\n",
       "      <th>injury</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>days_missed</th>\n",
       "      <th>cash_total</th>\n",
       "      <th>cash_per_day</th>\n",
       "      <th>reason_raw</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Anthony Rendon</td>\n",
       "      <td>3B</td>\n",
       "      <td>LAA</td>\n",
       "      <td>60-Day IL</td>\n",
       "      <td>Hip</td>\n",
       "      <td>2025-03-27</td>\n",
       "      <td>2025-09-28</td>\n",
       "      <td>186</td>\n",
       "      <td>37999986</td>\n",
       "      <td>204301.0</td>\n",
       "      <td>60-Day IL - Hip: 3/27/25-9/28/25</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Gerrit Cole</td>\n",
       "      <td>SP</td>\n",
       "      <td>NYY</td>\n",
       "      <td>60-Day IL</td>\n",
       "      <td>Elbow Tommy John</td>\n",
       "      <td>2025-03-27</td>\n",
       "      <td>2025-09-28</td>\n",
       "      <td>186</td>\n",
       "      <td>35999928</td>\n",
       "      <td>193548.0</td>\n",
       "      <td>60-Day IL - Elbow Tommy John: 3/27/25-9/28/25</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Kris Bryant</td>\n",
       "      <td>1B</td>\n",
       "      <td>COL</td>\n",
       "      <td>60-Day IL</td>\n",
       "      <td>Back</td>\n",
       "      <td>2025-04-13</td>\n",
       "      <td>2025-09-28</td>\n",
       "      <td>169</td>\n",
       "      <td>23623665</td>\n",
       "      <td>139785.0</td>\n",
       "      <td>60-Day IL - Back: 4/13/25-9/28/25</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Jordan Montgomery</td>\n",
       "      <td>SP</td>\n",
       "      <td>ARI</td>\n",
       "      <td>60-Day IL</td>\n",
       "      <td>Elbow Tommy John</td>\n",
       "      <td>2025-03-27</td>\n",
       "      <td>2025-09-28</td>\n",
       "      <td>186</td>\n",
       "      <td>22500048</td>\n",
       "      <td>120968.0</td>\n",
       "      <td>60-Day IL - Elbow Tommy John: 3/27/25-9/28/25</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Joe Musgrove</td>\n",
       "      <td>SP</td>\n",
       "      <td>SD</td>\n",
       "      <td>60-Day IL</td>\n",
       "      <td>Elbow Tommy John</td>\n",
       "      <td>2025-03-27</td>\n",
       "      <td>2025-09-28</td>\n",
       "      <td>186</td>\n",
       "      <td>20000022</td>\n",
       "      <td>107527.0</td>\n",
       "      <td>60-Day IL - Elbow Tommy John: 3/27/25-9/28/25</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank             player pos team    il_type            injury start_date  \\\n",
       "0     1     Anthony Rendon  3B  LAA  60-Day IL               Hip 2025-03-27   \n",
       "1     2        Gerrit Cole  SP  NYY  60-Day IL  Elbow Tommy John 2025-03-27   \n",
       "2     3        Kris Bryant  1B  COL  60-Day IL              Back 2025-04-13   \n",
       "3     4  Jordan Montgomery  SP  ARI  60-Day IL  Elbow Tommy John 2025-03-27   \n",
       "4     5       Joe Musgrove  SP   SD  60-Day IL  Elbow Tommy John 2025-03-27   \n",
       "\n",
       "    end_date  days_missed  cash_total  cash_per_day  \\\n",
       "0 2025-09-28          186    37999986      204301.0   \n",
       "1 2025-09-28          186    35999928      193548.0   \n",
       "2 2025-09-28          169    23623665      139785.0   \n",
       "3 2025-09-28          186    22500048      120968.0   \n",
       "4 2025-09-28          186    20000022      107527.0   \n",
       "\n",
       "                                      reason_raw  year  \n",
       "0               60-Day IL - Hip: 3/27/25-9/28/25  2025  \n",
       "1  60-Day IL - Elbow Tommy John: 3/27/25-9/28/25  2025  \n",
       "2              60-Day IL - Back: 4/13/25-9/28/25  2025  \n",
       "3  60-Day IL - Elbow Tommy John: 3/27/25-9/28/25  2025  \n",
       "4  60-Day IL - Elbow Tommy John: 3/27/25-9/28/25  2025  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years = [2025]\n",
    "tables, combined = scrape_spotrac_years(years)\n",
    "\n",
    "# Inspect\n",
    "{y: df.shape for y, df in tables.items()}\n",
    "combined.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3f3355",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.to_csv(\"mlb_injured_multi_year.csv\", index=False)\n",
    "# or per year:\n",
    "for y, df in tables.items():\n",
    "    df.to_parquet(f\"mlb_injured_{y}.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
