{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42a739bc",
   "metadata": {},
   "source": [
    "# Web Scraping Spotrac Data\n",
    "\n",
    "We had to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5be2650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import io\n",
    "from typing import Optional, Dict, List, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pybaseball as pyb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74d8b790",
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADERS = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/118.0.0.0 Safari/537.36\"\n",
    "    ),\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "}\n",
    "\n",
    "\n",
    "def build_url(year: int) -> str:\n",
    "    return f\"https://www.spotrac.com/mlb/injured/_/year/{year}/view/player\"\n",
    "\n",
    "\n",
    "def fetch_html(url: str, max_retries: int = 3, backoff: float = 2.0) -> Optional[str]:\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            resp = requests.get(url, headers=HEADERS, timeout=20)\n",
    "            if resp.status_code == 200 and \"text/html\" in resp.headers.get(\"Content-Type\", \"\"):\n",
    "                return resp.text\n",
    "            if resp.status_code in (403, 429, 503):\n",
    "                time.sleep(backoff * attempt)\n",
    "                continue\n",
    "            break\n",
    "        except requests.RequestException:\n",
    "            time.sleep(backoff * attempt)\n",
    "    return None\n",
    "\n",
    "\n",
    "def parse_table_with_pandas(html: str) -> Optional[pd.DataFrame]:\n",
    "    try:\n",
    "        tables = pd.read_html(io.StringIO(html))\n",
    "        if not tables:\n",
    "            return None\n",
    "        return max(tables, key=lambda t: t.shape[1])\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "\n",
    "def parse_table_with_bs4(html: str) -> Optional[pd.DataFrame]:\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    table = soup.find(\"table\")\n",
    "    if not table:\n",
    "        return None\n",
    "\n",
    "    thead = table.find(\"thead\")\n",
    "    if thead:\n",
    "        headers = [th.get_text(strip=True) for th in thead.find_all(\"th\")]\n",
    "    else:\n",
    "        first_row = table.find(\"tr\")\n",
    "        headers = [th.get_text(strip=True) for th in first_row.find_all([\"th\", \"td\"])] if first_row else []\n",
    "\n",
    "    rows = []\n",
    "    for tr in table.find_all(\"tr\"):\n",
    "        tds = tr.find_all(\"td\")\n",
    "        if not tds:\n",
    "            continue\n",
    "        rows.append([td.get_text(\" \", strip=True) for td in tds])\n",
    "\n",
    "    if not rows:\n",
    "        return None\n",
    "\n",
    "    max_len = max(len(r) for r in rows)\n",
    "    if len(headers) != max_len:\n",
    "        if len(headers) < max_len:\n",
    "            headers += [f\"col_{i+1}\" for i in range(len(headers), max_len)]\n",
    "        else:\n",
    "            headers = headers[:max_len]\n",
    "\n",
    "    return pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "\n",
    "def clean_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.columns = [c.strip().replace(\"\\n\", \" \").replace(\"  \", \" \") for c in df.columns]\n",
    "    df = df.dropna(axis=1, how=\"all\")\n",
    "    df = df.replace(\"\", pd.NA).dropna(how=\"all\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def try_requests_then_playwright(url: str) -> pd.DataFrame:\n",
    "    html = fetch_html(url)\n",
    "    if html:\n",
    "        for parser in (parse_table_with_pandas, parse_table_with_bs4):\n",
    "            df = parser(html)\n",
    "            if isinstance(df, pd.DataFrame) and not df.empty:\n",
    "                return clean_df(df)\n",
    "\n",
    "    try:\n",
    "        from playwright.sync_api import sync_playwright\n",
    "    except ImportError as e:\n",
    "        raise RuntimeError(\n",
    "            \"Requests parsing failed and Playwright is not installed.\\n\"\n",
    "            \"Install with:\\n  pip install playwright\\n  playwright install chromium\"\n",
    "        ) from e\n",
    "\n",
    "    with sync_playwright() as p:\n",
    "        browser = p.chromium.launch(headless=True)\n",
    "        context = browser.new_context(user_agent=HEADERS[\"User-Agent\"])\n",
    "        page = context.new_page()\n",
    "        page.goto(url, wait_until=\"domcontentloaded\", timeout=45000)\n",
    "        page.wait_for_selector(\"table\", timeout=20000)\n",
    "        content = page.content()\n",
    "        browser.close()\n",
    "\n",
    "    for parser in (parse_table_with_pandas, parse_table_with_bs4):\n",
    "        df = parser(content)\n",
    "        if isinstance(df, pd.DataFrame) and not df.empty:\n",
    "            return clean_df(df)\n",
    "\n",
    "    raise RuntimeError(\"Could not locate a data table on the page after rendering.\")\n",
    "\n",
    "\n",
    "# ---------------- Normalizer ----------------\n",
    "\n",
    "def _pick(df, *cands):\n",
    "    cand_lc = [c.lower() for c in df.columns]\n",
    "    for want in cands:\n",
    "        for i, c in enumerate(cand_lc):\n",
    "            if want in c:\n",
    "                return df.columns[i]\n",
    "    return None\n",
    "\n",
    "\n",
    "def normalize_spotrac_injured_df(raw: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parses multiple IL stints and preserves Spotrac's\n",
    "    displayed cash value exactly as shown for that year.\n",
    "    \"\"\"\n",
    "    df = raw.copy()\n",
    "\n",
    "    col_rank = _pick(df, \"rank\")\n",
    "    col_player = _pick(df, \"player\")\n",
    "    col_pos = _pick(df, \"pos\")\n",
    "    col_team = _pick(df, \"team\")\n",
    "    col_reason = _pick(df, \"reason\")\n",
    "    col_cash = _pick(df, \"cash\")\n",
    "\n",
    "    if any(c is None for c in [col_player, col_reason]):\n",
    "        raise ValueError(f\"Missing required columns. Found: {list(df.columns)}\")\n",
    "\n",
    "    def _clean(s):\n",
    "        return s.astype(str).str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "\n",
    "    if col_rank:\n",
    "        df[col_rank] = pd.to_numeric(df[col_rank], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    df[col_player] = _clean(df[col_player])\n",
    "    if col_pos:\n",
    "        df[col_pos] = _clean(df[col_pos])\n",
    "    if col_team:\n",
    "        df[col_team] = _clean(df[col_team])\n",
    "\n",
    "    # --- Clean cash column ONLY (no math, no inference) ---\n",
    "    if col_cash:\n",
    "        df[col_cash] = (\n",
    "            df[col_cash]\n",
    "            .astype(str)\n",
    "            .str.replace(r\"[$,]\", \"\", regex=True)\n",
    "            .replace(\"nan\", pd.NA)\n",
    "        )\n",
    "        df[col_cash] = pd.to_numeric(df[col_cash], errors=\"coerce\")\n",
    "\n",
    "    # --- Regex for IL stints ---\n",
    "    rx_entry = re.compile(\n",
    "        r\"\"\"\n",
    "        (?P<il>[^:,]+?(?:IL|List|Suspension|Restricted(?:\\s+List)?))\n",
    "        (?:\\s*-\\s*(?P<inj>[^:,]+?))?\n",
    "        \\s*:\\s*\n",
    "        (?P<start>\\d{1,2}/\\d{1,2}/\\d{2})\n",
    "        \\s*-\\s*\n",
    "        (?P<end>\\d{1,2}/\\d{1,2}/\\d{2})\n",
    "        \"\"\",\n",
    "        re.IGNORECASE | re.VERBOSE\n",
    "    )\n",
    "\n",
    "    records = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        base = {\n",
    "            \"rank\": row[col_rank] if col_rank else pd.NA,\n",
    "            \"player\": row[col_player],\n",
    "            \"pos\": row[col_pos] if col_pos else pd.NA,\n",
    "            \"team\": row[col_team] if col_team else pd.NA,\n",
    "            \"cash_total\": row[col_cash] if col_cash else pd.NA,\n",
    "        }\n",
    "\n",
    "        text = str(row[col_reason])\n",
    "        matches = list(rx_entry.finditer(text))\n",
    "\n",
    "        if matches:\n",
    "            for m in matches:\n",
    "                rec = dict(base)\n",
    "                rec[\"il_type\"] = (m.group(\"il\") or \"\").strip()\n",
    "                rec[\"injury\"] = (m.group(\"inj\") or \"\").strip()\n",
    "                rec[\"start_date\"] = pd.to_datetime(\n",
    "                    m.group(\"start\"), format=\"%m/%d/%y\", errors=\"coerce\"\n",
    "                )\n",
    "                rec[\"end_date\"] = pd.to_datetime(\n",
    "                    m.group(\"end\"), format=\"%m/%d/%y\", errors=\"coerce\"\n",
    "                )\n",
    "                rec[\"reason_raw\"] = text\n",
    "                records.append(rec)\n",
    "        else:\n",
    "            rec = dict(base)\n",
    "            rec[\"il_type\"] = \"\"\n",
    "            rec[\"injury\"] = \"\"\n",
    "            rec[\"start_date\"] = pd.NaT\n",
    "            rec[\"end_date\"] = pd.NaT\n",
    "            rec[\"reason_raw\"] = text\n",
    "            records.append(rec)\n",
    "\n",
    "    out = pd.DataFrame.from_records(records)\n",
    "\n",
    "    want = [\n",
    "        \"rank\", \"player\", \"pos\", \"team\",\n",
    "        \"cash_total\",\n",
    "        \"il_type\", \"injury\", \"start_date\", \"end_date\",\n",
    "        \"reason_raw\",\n",
    "    ]\n",
    "    return out[[c for c in want if c in out.columns]]\n",
    "\n",
    "# ---------------- Multi-year API ----------------\n",
    "\n",
    "def scrape_spotrac_years(years: List[int], sleep_sec: float = 1.0) -> Tuple[Dict[int, pd.DataFrame], pd.DataFrame]:\n",
    "    tables = {}\n",
    "    frames = []\n",
    "    for yr in years:\n",
    "        url = build_url(yr)\n",
    "        raw = try_requests_then_playwright(url)\n",
    "        clean = normalize_spotrac_injured_df(raw)\n",
    "        clean[\"year\"] = yr\n",
    "        tables[yr] = clean\n",
    "        frames.append(clean)\n",
    "        if sleep_sec:\n",
    "            time.sleep(sleep_sec)\n",
    "\n",
    "    combined = pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()\n",
    "    return tables, combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f5a9bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>player</th>\n",
       "      <th>pos</th>\n",
       "      <th>team</th>\n",
       "      <th>cash_total</th>\n",
       "      <th>il_type</th>\n",
       "      <th>injury</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>reason_raw</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Miguel Cabrera</td>\n",
       "      <td>DH</td>\n",
       "      <td>DET</td>\n",
       "      <td>22580600</td>\n",
       "      <td>10-Day IL</td>\n",
       "      <td>Hamstring</td>\n",
       "      <td>2018-05-04</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>10-Day IL - Hamstring: 5/4/18-6/1/18  10-Day I...</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Miguel Cabrera</td>\n",
       "      <td>DH</td>\n",
       "      <td>DET</td>\n",
       "      <td>22580600</td>\n",
       "      <td>10-Day IL</td>\n",
       "      <td>Biceps</td>\n",
       "      <td>2018-06-13</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>10-Day IL - Hamstring: 5/4/18-6/1/18  10-Day I...</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Jacoby Ellsbury</td>\n",
       "      <td>CF</td>\n",
       "      <td>NYY</td>\n",
       "      <td>21256477</td>\n",
       "      <td>60-Day IL</td>\n",
       "      <td>Oblique</td>\n",
       "      <td>2018-03-29</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>60-Day IL - Oblique: 3/29/18-10/1/18</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Yoenis Céspedes</td>\n",
       "      <td>LF</td>\n",
       "      <td>NYM</td>\n",
       "      <td>21204304</td>\n",
       "      <td>10-Day IL</td>\n",
       "      <td>Hip</td>\n",
       "      <td>2018-05-16</td>\n",
       "      <td>2018-07-20</td>\n",
       "      <td>10-Day IL - Hip: 5/16/18-7/20/18  60-Day IL - ...</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Yoenis Céspedes</td>\n",
       "      <td>LF</td>\n",
       "      <td>NYM</td>\n",
       "      <td>21204304</td>\n",
       "      <td>60-Day IL</td>\n",
       "      <td>Heel</td>\n",
       "      <td>2018-07-24</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>10-Day IL - Hip: 5/16/18-7/20/18  60-Day IL - ...</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>628</td>\n",
       "      <td>Cade Horton</td>\n",
       "      <td>SP</td>\n",
       "      <td>CHC</td>\n",
       "      <td>16344</td>\n",
       "      <td>15-Day IL</td>\n",
       "      <td>Ribs</td>\n",
       "      <td>2025-09-25</td>\n",
       "      <td>2025-09-28</td>\n",
       "      <td>15-Day IL - Ribs: 9/25/25-9/28/25</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>629</td>\n",
       "      <td>Everson Pereira</td>\n",
       "      <td>OF</td>\n",
       "      <td>TB</td>\n",
       "      <td>12258</td>\n",
       "      <td>10-Day IL</td>\n",
       "      <td>Back</td>\n",
       "      <td>2025-09-26</td>\n",
       "      <td>2025-09-28</td>\n",
       "      <td>10-Day IL - Back: 9/26/25-9/28/25</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6334</th>\n",
       "      <td>630</td>\n",
       "      <td>Brett Baty</td>\n",
       "      <td>2B</td>\n",
       "      <td>NYM</td>\n",
       "      <td>8322</td>\n",
       "      <td>10-Day IL</td>\n",
       "      <td>Oblique</td>\n",
       "      <td>2025-09-27</td>\n",
       "      <td>2025-09-28</td>\n",
       "      <td>10-Day IL - Oblique: 9/27/25-9/28/25</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6335</th>\n",
       "      <td>631</td>\n",
       "      <td>Nick Frasso</td>\n",
       "      <td>SP</td>\n",
       "      <td>LAD</td>\n",
       "      <td>1420</td>\n",
       "      <td>60-Day IL</td>\n",
       "      <td>Undisclosed</td>\n",
       "      <td>2025-09-27</td>\n",
       "      <td>2025-09-28</td>\n",
       "      <td>60-Day IL - Undisclosed: 9/27/25-9/28/25</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6336</th>\n",
       "      <td>632</td>\n",
       "      <td>Vaughn Grissom</td>\n",
       "      <td>2B</td>\n",
       "      <td>BOS</td>\n",
       "      <td>0</td>\n",
       "      <td>60-Day IL</td>\n",
       "      <td>Foot</td>\n",
       "      <td>2025-09-09</td>\n",
       "      <td>2025-09-28</td>\n",
       "      <td>60-Day IL - Foot: 9/9/25-9/28/25</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6337 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rank           player pos team  cash_total    il_type       injury  \\\n",
       "0        1   Miguel Cabrera  DH  DET    22580600  10-Day IL    Hamstring   \n",
       "1        1   Miguel Cabrera  DH  DET    22580600  10-Day IL       Biceps   \n",
       "2        2  Jacoby Ellsbury  CF  NYY    21256477  60-Day IL      Oblique   \n",
       "3        3  Yoenis Céspedes  LF  NYM    21204304  10-Day IL          Hip   \n",
       "4        3  Yoenis Céspedes  LF  NYM    21204304  60-Day IL         Heel   \n",
       "...    ...              ...  ..  ...         ...        ...          ...   \n",
       "6332   628      Cade Horton  SP  CHC       16344  15-Day IL         Ribs   \n",
       "6333   629  Everson Pereira  OF   TB       12258  10-Day IL         Back   \n",
       "6334   630       Brett Baty  2B  NYM        8322  10-Day IL      Oblique   \n",
       "6335   631      Nick Frasso  SP  LAD        1420  60-Day IL  Undisclosed   \n",
       "6336   632   Vaughn Grissom  2B  BOS           0  60-Day IL         Foot   \n",
       "\n",
       "     start_date   end_date                                         reason_raw  \\\n",
       "0    2018-05-04 2018-06-01  10-Day IL - Hamstring: 5/4/18-6/1/18  10-Day I...   \n",
       "1    2018-06-13 2018-10-01  10-Day IL - Hamstring: 5/4/18-6/1/18  10-Day I...   \n",
       "2    2018-03-29 2018-10-01               60-Day IL - Oblique: 3/29/18-10/1/18   \n",
       "3    2018-05-16 2018-07-20  10-Day IL - Hip: 5/16/18-7/20/18  60-Day IL - ...   \n",
       "4    2018-07-24 2018-10-01  10-Day IL - Hip: 5/16/18-7/20/18  60-Day IL - ...   \n",
       "...         ...        ...                                                ...   \n",
       "6332 2025-09-25 2025-09-28                  15-Day IL - Ribs: 9/25/25-9/28/25   \n",
       "6333 2025-09-26 2025-09-28                  10-Day IL - Back: 9/26/25-9/28/25   \n",
       "6334 2025-09-27 2025-09-28               10-Day IL - Oblique: 9/27/25-9/28/25   \n",
       "6335 2025-09-27 2025-09-28           60-Day IL - Undisclosed: 9/27/25-9/28/25   \n",
       "6336 2025-09-09 2025-09-28                   60-Day IL - Foot: 9/9/25-9/28/25   \n",
       "\n",
       "      year  \n",
       "0     2018  \n",
       "1     2018  \n",
       "2     2018  \n",
       "3     2018  \n",
       "4     2018  \n",
       "...    ...  \n",
       "6332  2025  \n",
       "6333  2025  \n",
       "6334  2025  \n",
       "6335  2025  \n",
       "6336  2025  \n",
       "\n",
       "[6337 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# years = [2015, 2020, 2021, 2022, 2023, 2024, 2025]\n",
    "\n",
    "[i for i in range(2018, 2026)]\n",
    "\n",
    "tables, combined = scrape_spotrac_years([i for i in range(2018, 2026)])\n",
    "\n",
    "# Inspect\n",
    "{y: df.shape for y, df in tables.items()}\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5abe853",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.to_csv(\"mlb_injuries.csv\", index=False)\n",
    "# # or per year:\n",
    "# for y, df in tables.items():\n",
    "#     df.to_parquet(f\"mlb_injured_{y}.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74f19b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total IL cash across all positions:       $1019085824\n",
      "Total IL cash for pitchers:       $640815094\n",
      "Total Arm IL cash for pitchers:       $461559848\n",
      "Total days spent on IL for arm injuries:       22665 days\n",
      "Percentage of Days on IL by Arm Injury: 57.75%\n"
     ]
    }
   ],
   "source": [
    "## 2025 pitcher injury context\n",
    "combined_2025 = combined[combined['year'] == 2025].reset_index(drop=True).copy()\n",
    "pitcher_injuries = ['Biceps', 'Arm', 'Elbow', 'Shoulder', 'Elbow Tommy John', 'Ulnar Nerve',]\n",
    "\n",
    "print(f\"Total IL cash across all positions: \\\n",
    "      ${combined_2025.groupby('player')['cash_total'].first().sum()}\")\n",
    "print(f\"Total IL cash for pitchers: \\\n",
    "      ${combined_2025[(combined_2025['pos'].isin(['P', 'SP', 'RP']))].groupby('player')['cash_total'].first().sum()}\")\n",
    "print(f\"Total Arm IL cash for pitchers: \\\n",
    "      ${combined_2025[(combined_2025['pos'].isin(['P', 'SP', 'RP'])) & (combined_2025['injury'].isin(pitcher_injuries))].groupby('player')['cash_total'].first().sum()}\")\n",
    "\n",
    "### making it datetime dtype & creating days_on_il col\n",
    "combined_2025['start_date'] = pd.to_datetime(combined_2025['start_date'])\n",
    "combined_2025['end_date'] = pd.to_datetime(combined_2025['end_date'])\n",
    "combined_2025['days_on_il'] = ((combined_2025['end_date'] - combined_2025['start_date']).dt.days) + 1\n",
    "\n",
    "print(f\"Total days spent on IL for arm injuries: \\\n",
    "      {combined_2025[(combined_2025['pos'].isin(['P', 'SP', 'RP'])) & (combined_2025['injury'].isin(pitcher_injuries))]['days_on_il'].sum()} days\")\n",
    "\n",
    "combined_2025['injury_type_group'] = combined_2025['injury'].apply(lambda x: 'Arm Injury' if x in pitcher_injuries else x)\n",
    "injury_group_totals = sorted(combined_2025.groupby('injury_type_group')['days_on_il'].sum() / combined_2025.groupby('injury_type_group')['days_on_il'].sum().sum())[-1]\n",
    "print(f\"Percentage of Days on IL by Arm Injury: {injury_group_totals*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1a67b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
